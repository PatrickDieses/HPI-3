{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christianwarmuth/openhpi-kipraxis/blob/main/Woche%202/2_6_Recommender_Systems_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb899884",
      "metadata": {
        "id": "eb899884"
      },
      "source": [
        "## Installieren aller Pakete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "445034f6",
      "metadata": {
        "id": "445034f6"
      },
      "outputs": [],
      "source": [
        "# Hier die Kaggle Credentials einfügen (ohne Anführungszeichen)\n",
        "\n",
        "%env KAGGLE_USERNAME=openhpi\n",
        "%env KAGGLE_KEY=das_ist_der_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be37b5c2",
      "metadata": {
        "id": "be37b5c2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from keras.layers import Input, Embedding, Reshape, Dot, Concatenate, Dense, Dropout\n",
        "from keras.models import Model\n",
        "\n",
        "from sklearn.decomposition import NMF\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0825531",
      "metadata": {
        "id": "b0825531"
      },
      "source": [
        "# Methodendefinitionen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82effffe",
      "metadata": {
        "id": "82effffe"
      },
      "outputs": [],
      "source": [
        "# Credits: https://www.kaggle.com/morrisb/how-to-recommend-anything-deep-recommender\n",
        "\n",
        "def mf_model(df, train, test,  emb_size=20):\n",
        "    # Create user- & movie-id mapping\n",
        "    user_id_mapping = {id:i for i, id in enumerate(df['userId'].unique())}\n",
        "    movie_id_mapping = {id:i for i, id in enumerate(df['movieId'].unique())}\n",
        "    \n",
        "    \n",
        "    # Create correctly mapped train- & testset\n",
        "    train_user_data = train['userId'].map(user_id_mapping)\n",
        "    train_movie_data = train['movieId'].map(movie_id_mapping)\n",
        "    \n",
        "    test_user_data = test['userId'].map(user_id_mapping)\n",
        "    test_movie_data = test['movieId'].map(movie_id_mapping)\n",
        "    \n",
        "    \n",
        "    # Get input variable-sizes\n",
        "    users = len(user_id_mapping)\n",
        "    movies = len(movie_id_mapping)\n",
        "    embedding_size = emb_size\n",
        "    \n",
        "    \n",
        "    ##### Create model\n",
        "    # Set input layers\n",
        "    user_id_input = Input(shape=[1], name='user')\n",
        "    movie_id_input = Input(shape=[1], name='movie')\n",
        "    \n",
        "    # Create embedding layers for users and movies\n",
        "    user_embedding = Embedding(output_dim=embedding_size, \n",
        "                               input_dim=users,\n",
        "                               input_length=1, \n",
        "                               name='user_embedding')(user_id_input)\n",
        "    movie_embedding = Embedding(output_dim=embedding_size, \n",
        "                                input_dim=movies,\n",
        "                                input_length=1, \n",
        "                                name='item_embedding')(movie_id_input)\n",
        "    \n",
        "    # Reshape the embedding layers\n",
        "    user_vector = Reshape([embedding_size])(user_embedding)\n",
        "    movie_vector = Reshape([embedding_size])(movie_embedding)\n",
        "    \n",
        "    # Compute dot-product of reshaped embedding layers as prediction\n",
        "    y = Dot(1, normalize=False)([user_vector, movie_vector])\n",
        "    \n",
        "    # Setup model\n",
        "    model = Model(inputs=[user_id_input, movie_id_input], outputs=y)\n",
        "    model.compile(loss='mse', optimizer='adam')\n",
        "    return train_user_data, train_movie_data, test_user_data, test_movie_data, model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43c1cf77",
      "metadata": {
        "id": "43c1cf77"
      },
      "source": [
        "# 2.6 Recommender Systems 2: \n",
        "## Vorschlagssystem mit Collaborative Filtering\n",
        "\n",
        "<img width=70% src=\"https://raw.githubusercontent.com/christianwarmuth/openhpi-kipraxis/main/images/jakob-owens-CiUR8zISX60-unsplash%20(2).jpg\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff5e3bf1",
      "metadata": {
        "id": "ff5e3bf1"
      },
      "source": [
        "Datensatz: \n",
        "\n",
        "### The Movies Dataset\n",
        "Metadaten für über 45.000 Filme. 26 Millionen Bewertungen von über 270.000 NutzerInnen.\n",
        "\n",
        "Quelle: kaggle.com"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5270500",
      "metadata": {
        "id": "f5270500"
      },
      "source": [
        "## Was wir erreichen wollen\n",
        "\n",
        "In der Theorie-Einheit haben wir die Methodik des Collaborative Filtering vorgestellt. Diese Methode nutzt Ähnlichkeiten in der Interkation zwischen NutzerInnen und den Filmen, um Filme vorzuschlagen. Beim Collaborative Filtering werden Vorschläge gegeben, wie eine Nutzerin oder ein Nutzer einen Film bewerten würde, der noch nicht gesehen wurde. Dann würde man der Person einen Film mit einer hohen vorhergesagten Bewertung vorschlagen.  \n",
        "\n",
        "<img width=40% src=\"https://raw.githubusercontent.com/christianwarmuth/openhpi-kipraxis/main/images/collaborative_filtering.jpg\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92f831a8",
      "metadata": {
        "id": "92f831a8"
      },
      "source": [
        "# Einlesen der Daten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfd8e57d",
      "metadata": {
        "id": "bfd8e57d"
      },
      "outputs": [],
      "source": [
        "!pip3 install kaggle\n",
        "!kaggle datasets download -d rounakbanik/the-movies-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Xp9Pmx1xuKjE",
      "metadata": {
        "id": "Xp9Pmx1xuKjE"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"the-movies-dataset.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PKvsIawyuLBM",
      "metadata": {
        "id": "PKvsIawyuLBM"
      },
      "outputs": [],
      "source": [
        "df_film_ratings = pd.read_csv(\"ratings_small.csv\", low_memory=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8253983",
      "metadata": {
        "id": "a8253983"
      },
      "source": [
        "Sehen wir uns erneut einmal ein paar Einträge aus dem Datensatz an. Hierbei fällt auf, dass wir die Spalte \"Timestamp\" für unseren Anwendungsfall nicht brauchen und daher verwerfen können. Wir sollten zudem noch die Bewertungen \"mischen\". "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48209c0a",
      "metadata": {
        "id": "48209c0a"
      },
      "outputs": [],
      "source": [
        "df_film_ratings.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea3ccb5a",
      "metadata": {
        "id": "ea3ccb5a"
      },
      "outputs": [],
      "source": [
        "df_film_ratings = df_film_ratings.drop(\"timestamp\", axis=1) # Entfernen der Spalte Timestamp\n",
        "df_film_ratings = df_film_ratings.sample(frac=1).reset_index(drop=True) # Durchmischen der Bewertungen"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7719efb9",
      "metadata": {
        "id": "7719efb9"
      },
      "source": [
        "Wie möglicherweise direkt beim Import aufgefallen ist, importieren wir hier nur die kleine Version des Datensatzes. Für die gesamte Größe des Datensatzes ist jedoch die Trainingszeit deutlich höher, weswegen wir zunächst darauf verzichten. Wer das gesamte File einlesen will, bitte \"ratings.csv\" statt \"ratings_small.csv\" verwenden. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "113bb047",
      "metadata": {
        "id": "113bb047"
      },
      "source": [
        "# Train Test Split "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8c31ec4",
      "metadata": {
        "id": "c8c31ec4"
      },
      "source": [
        "Beim Collaborative Filtering wollen wir die Güte unserer Vorhersage prüfen. Im Gegensatz zum vorgestellten Content-based Filtering haben wir hier \"Labels\", da wir die Bewertungen einzelner NutzerInnen für die einzelnen Filme haben. Somit können wir einen Teil im Training dem Modell vorenthalten und darauf die Güte unseres Modells bewerten. \n",
        "\n",
        "Im Folgenden Code-Abschnitt teilen wir den Datensatz in 80% Trainingsdaten und 20% Testdaten."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9802646a",
      "metadata": {
        "id": "9802646a"
      },
      "outputs": [],
      "source": [
        "split_factor = 0.2\n",
        "n = int(split_factor*len(df_film_ratings))\n",
        "\n",
        "df_train = df_film_ratings[:-n]\n",
        "df_test = df_film_ratings[-n:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4016cdc",
      "metadata": {
        "id": "c4016cdc"
      },
      "source": [
        "# Matrix Faktorisierung - ein Beispiel\n",
        "\n",
        "In Einheit 2.2 Einführung Recommender Systems haben wir kurz die Methode Matrix Faktorisierung vorgestellt. Hier wollen wir zunächst mal ein einfaches Beispiel geben."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7acd47fd",
      "metadata": {
        "id": "7acd47fd"
      },
      "outputs": [],
      "source": [
        "X = np.array([[1, 1, 5], [2, 1, 3], [3, 1.2, 8.7], [4, 1, 3], [5, 0.8, 9], [6, 1, 1.5]])\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d408f5bd",
      "metadata": {
        "id": "d408f5bd"
      },
      "outputs": [],
      "source": [
        "model = NMF(n_components=2, init='random', random_state=0, verbose=False)\n",
        "W = model.fit_transform(X)\n",
        "H = model.components_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9795449a",
      "metadata": {
        "id": "9795449a"
      },
      "outputs": [],
      "source": [
        "print(np.subtract(X, np.dot(W,H)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d4048f9",
      "metadata": {
        "id": "7d4048f9"
      },
      "source": [
        "## Root Mean Squared Error\n",
        "\n",
        "Der Root Mean Squared Error (RMSE) ist ein Standardverfahren zur Messung des Fehlers eines Modells bei der Vorhersage quantitativer Daten. Formal ist er wie folgt definiert:\n",
        "\n",
        "$$ RMSE = \\sqrt{ \\sum_{i=1}^{n} \\frac{\\left ( \\hat{y}_{i} - y_{i}\\right )^2}{n}} $$\n",
        "\n",
        "In natürlicher Sprache ist der RMSE die Wurzel aus dem MSE (Mean Squared Error). Der Mean Squared Error beschreibt den Durchschnitt der quadrierten Abweichungen (Prediction vs. realer Wert)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f31cccb0",
      "metadata": {
        "id": "f31cccb0"
      },
      "source": [
        "Nun werden wir auch einmal den RMSE für unser aktuelles Beispiel berechnen:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce963fee",
      "metadata": {
        "id": "ce963fee"
      },
      "outputs": [],
      "source": [
        "rmse = np.sqrt(mean_squared_error(y_pred=X, y_true=np.dot(W,H)))\n",
        "print(\"RMSE: \" + str(rmse))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27e8e3a8",
      "metadata": {
        "id": "27e8e3a8"
      },
      "source": [
        "# Matrix Faktorisierung - Film Vorschlagssystem"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6964ecd8",
      "metadata": {
        "id": "6964ecd8"
      },
      "source": [
        "Oben haben wir die Matrix Faktorisierung anhang eines Beispiels gezeigt. Nun wollen wir die Methode auf unseren Datensatz anwenden. Hierzu nutzen wir eine [existierende Methode](https://www.kaggle.com/morrisb/how-to-recommend-anything-deep-recommender), welche wir einfach aufrufen können. Zunächst müssen wir das Modell einmal definieren. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a92c0db",
      "metadata": {
        "id": "0a92c0db"
      },
      "outputs": [],
      "source": [
        "train_user_data, train_movie_data, test_user_data, test_movie_data, model = mf_model(df_film_ratings, df_train, df_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f7c01b7",
      "metadata": {
        "id": "4f7c01b7"
      },
      "source": [
        "Nachdem wir das Modell nun definiert haben, trainieren wir das Modell. Für das Training müssen wir noch einige \"Stellschrauben\" oder Hyperparameter setzen. So zum Beispiel die Epochen (Anzahl der Durchläufe über den gesamten Datensatz) oder die Batch-Size (Anzahl der Elemente, die trainiert werden, bevor die internen Parameter automatisch angepasst werden)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5592cb9b",
      "metadata": {
        "id": "5592cb9b"
      },
      "outputs": [],
      "source": [
        "model.fit([train_user_data, train_movie_data],\n",
        "          df_train['rating'],\n",
        "          batch_size=256, \n",
        "          epochs=10,\n",
        "          shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41fc58ae",
      "metadata": {
        "id": "41fc58ae"
      },
      "source": [
        "Nun werden wir unser Modell noch testen auf den Test-Daten. Diesen Teil der Daten hat das Modell bisher noch nicht gesehen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa868278",
      "metadata": {
        "id": "fa868278"
      },
      "outputs": [],
      "source": [
        "# Test model\n",
        "y_pred = model.predict([test_user_data, test_movie_data])\n",
        "y_true = df_test['rating'].values\n",
        "\n",
        "#  Berechne Root Mean Squared Error\n",
        "rmse = np.sqrt(mean_squared_error(y_pred=y_pred, y_true=y_true))\n",
        "print('RMSE: '+ str(rmse))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73937e93",
      "metadata": {
        "id": "73937e93"
      },
      "source": [
        "Das ist zunächst mal eine erste Auswertung unseres Modells. Eine detailliertere Auswertung werden wir in Einheit **2.7 Ergebnis und Auswertung** etwas genauer ansehen. Man sieht aber hier bereits gut, dass sich die Interpretation dieses Wertes schwieriger gestaltet als die tatsächlichen Film-Vorschläge in Einheit 2.6. Darauf werden wir im folgenden Notebook noch etwas genauer eingehen. "
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "2.6 Recommender Systems 2.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
    },
    "kernelspec": {
      "display_name": "Python 3.7.9 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
