{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "ki-praxis",
      "language": "python",
      "name": "ki-praxis"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "2.7 Ergebnis und Auswertung.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christianwarmuth/openhpi-kipraxis/blob/main/Woche%202/2_7_Ergebnis_und_Auswertung.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a63a217a"
      },
      "source": [
        "## Installieren aller Pakete"
      ],
      "id": "a63a217a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83b0780b"
      },
      "source": [
        "# Hier die Kaggle Credentials einfügen (ohne Anführungszeichen)\n",
        "\n",
        "%env KAGGLE_USERNAME=openhpi\n",
        "%env KAGGLE_KEY=das_ist_der_key"
      ],
      "id": "83b0780b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11d186e3"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from keras.layers import Input, Embedding, Reshape, Dot, Concatenate, Dense, Dropout\n",
        "from keras.models import Model\n",
        "\n",
        "from sklearn.decomposition import NMF\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [5, 3]\n",
        "plt.rcParams['figure.dpi'] = 150 "
      ],
      "id": "11d186e3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3142482d"
      },
      "source": [
        "# Content-based Filtering"
      ],
      "id": "3142482d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "245bfa32"
      },
      "source": [
        "!pip3 install kaggle\n",
        "!kaggle datasets download -d rounakbanik/the-movies-dataset"
      ],
      "id": "245bfa32",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qESmflx93Mg7"
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"the-movies-dataset.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"\")"
      ],
      "id": "qESmflx93Mg7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6bglyEi3OuB"
      },
      "source": [
        "df_film_metadata = pd.read_csv(\"movies_metadata.csv\", low_memory=False)"
      ],
      "id": "t6bglyEi3OuB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0d27ee96"
      },
      "source": [
        "df_film_metadata = df_film_metadata[df_film_metadata['overview'].notna()]\n",
        "df_film_metadata = df_film_metadata.reset_index()\n",
        "\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(df_film_metadata['overview'])\n",
        "\n",
        "title_to_index = pd.Series(df_film_metadata.index, index=df_film_metadata['title'])\n",
        "\n",
        "movie_matrix=csr_matrix(tfidf_matrix)\n",
        "model_knn= NearestNeighbors(metric='cosine', algorithm='auto', n_neighbors=10, n_jobs=-1)\n",
        "\n",
        "def recommend_films_by_title_knn(title, data, model, n_neighbors):\n",
        "    model.fit(data)\n",
        "    movie_idx = title_to_index[title]\n",
        "    sim_scores, movie_indices = model.kneighbors(data[movie_idx], n_neighbors=n_neighbors+1)\n",
        "    sim_scores = sim_scores.squeeze().tolist()\n",
        "    recommendation_list = []\n",
        "    for idx, movie_idx in enumerate(movie_indices.squeeze().tolist()):\n",
        "        recommendation_list.append({'Title':df_film_metadata['title'][movie_idx],'Distance':sim_scores[idx]})\n",
        "    return pd.DataFrame(recommendation_list).sort_values(by=['Distance'], ascending=False).reset_index(drop=True)[:-1]"
      ],
      "id": "0d27ee96",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92d36439"
      },
      "source": [
        "# Collaborative Filtering"
      ],
      "id": "92d36439"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cadb35a"
      },
      "source": [
        "df_film_ratings = pd.read_csv(\"ratings_small.csv\", low_memory=False)"
      ],
      "id": "7cadb35a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59e29d70"
      },
      "source": [
        "df_film_ratings = df_film_ratings.drop(\"timestamp\", axis=1) # Entfernen des Spalte Timestamp\n",
        "df_film_ratings = df_film_ratings.sample(frac=1).reset_index(drop=True) # Durchmischen der Bewertungen\n",
        "\n",
        "split_factor = 0.2\n",
        "n = int(split_factor*len(df_film_ratings))\n",
        "\n",
        "df_train = df_film_ratings[:-n]\n",
        "df_test = df_film_ratings[-n:]\n",
        "\n",
        "# Credits: https://www.kaggle.com/morrisb/how-to-recommend-anything-deep-recommender\n",
        "\n",
        "def mf_model(df, train, test,  emb_size=20):\n",
        "    # Create user- & movie-id mapping\n",
        "    user_id_mapping = {id:i for i, id in enumerate(df['userId'].unique())}\n",
        "    movie_id_mapping = {id:i for i, id in enumerate(df['movieId'].unique())}\n",
        "    \n",
        "    \n",
        "    # Create correctly mapped train- & testset\n",
        "    train_user_data = train['userId'].map(user_id_mapping)\n",
        "    train_movie_data = train['movieId'].map(movie_id_mapping)\n",
        "    \n",
        "    test_user_data = test['userId'].map(user_id_mapping)\n",
        "    test_movie_data = test['movieId'].map(movie_id_mapping)\n",
        "    \n",
        "    \n",
        "    # Get input variable-sizes\n",
        "    users = len(user_id_mapping)\n",
        "    movies = len(movie_id_mapping)\n",
        "    embedding_size = emb_size\n",
        "    \n",
        "    \n",
        "    ##### Create model\n",
        "    # Set input layers\n",
        "    user_id_input = Input(shape=[1], name='user')\n",
        "    movie_id_input = Input(shape=[1], name='movie')\n",
        "    \n",
        "    # Create embedding layers for users and movies\n",
        "    user_embedding = Embedding(output_dim=embedding_size, \n",
        "                               input_dim=users,\n",
        "                               input_length=1, \n",
        "                               name='user_embedding')(user_id_input)\n",
        "    movie_embedding = Embedding(output_dim=embedding_size, \n",
        "                                input_dim=movies,\n",
        "                                input_length=1, \n",
        "                                name='item_embedding')(movie_id_input)\n",
        "    \n",
        "    # Reshape the embedding layers\n",
        "    user_vector = Reshape([embedding_size])(user_embedding)\n",
        "    movie_vector = Reshape([embedding_size])(movie_embedding)\n",
        "    \n",
        "    # Compute dot-product of reshaped embedding layers as prediction\n",
        "    y = Dot(1, normalize=False)([user_vector, movie_vector])\n",
        "    \n",
        "    # Setup model\n",
        "    model = Model(inputs=[user_id_input, movie_id_input], outputs=y)\n",
        "    model.compile(loss='mse', optimizer='adam')\n",
        "    return train_user_data, train_movie_data, test_user_data, test_movie_data, model\n",
        "\n",
        "train_user_data, train_movie_data, test_user_data, test_movie_data, model = mf_model(df_film_ratings, df_train, df_test)\n",
        "\n",
        "history = model.fit([train_user_data, train_movie_data],\n",
        "          df_train['rating'],\n",
        "          batch_size=256, \n",
        "          validation_split=0.1,\n",
        "          epochs=10,\n",
        "          shuffle=True)"
      ],
      "id": "59e29d70",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1f000c7"
      },
      "source": [
        "# 2.7 Ergebnis und Auswertung\n",
        "\n",
        "<img width=70% src=\"https://raw.githubusercontent.com/christianwarmuth/openhpi-kipraxis/main/images/jakob-owens-CiUR8zISX60-unsplash%20(2).jpg\">\n"
      ],
      "id": "d1f000c7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfb5055a"
      },
      "source": [
        "In diesem Notebook wollen wir einmal das erstellte Content-based Recommendation System und das Collaborative Filtering Recommendation System auswerten. Auch wenn wir in beiden Fällen jeweils Vorschläge für Filme geben, werden wir sehen, dass die Möglichkeiten zur Auswertung sich deutlich unterscheiden werden. "
      ],
      "id": "dfb5055a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f9cfddb"
      },
      "source": [
        "## Content-based Recommendation - Ergebnis und Auswertung"
      ],
      "id": "3f9cfddb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe118429"
      },
      "source": [
        "Die verwendete Content-based Recommendation ist eine unsupervised Machine Learning Technik. Wir haben hierbei keinerlei Labels, ob ein Film einem anderen inhaltlich ähnlich ist. Die inhaltiche Ähnlichkeit ist daher sehr schwer zu überprüfen. Bei unsupervised Techniken ist es meist nur für Domain-Experten möglich, die \"Güte\" der Ergebnisse zu bewerten."
      ],
      "id": "fe118429"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bbca97e"
      },
      "source": [
        "Wir können uns erneut einmal die Vorschläge zu dem Film \"Golden Eye\" ausgeben lassen. Golden Eye ist ein Film aus der James Bond Reihe. Wir sehen hier, dass viele der Vorschläge tatsächlich andere James Bond Filme sind (z.B: Casion Royale, Never Say Never Again, You Only Live Twice, Octopussy, Live and Let Die, Licence to Kill)."
      ],
      "id": "9bbca97e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e121ea8"
      },
      "source": [
        "recommend_films_by_title_knn(\"GoldenEye\", movie_matrix, model_knn, n_neighbors=10)"
      ],
      "id": "3e121ea8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90f4ca3e"
      },
      "source": [
        "Nun sehen wir uns einmal die Kurzbeschreibungen der Filme in der Liste an, die keine James Bond Filme sind. Das gibt uns vielleicht einen Hinweis, warum die Filme inhaltlich ähnlich zu James Bond Filmen gesehen werden.  "
      ],
      "id": "90f4ca3e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc5fecf2"
      },
      "source": [
        "print(\"The Way of the Dragon: \" + df_film_metadata[\"overview\"][title_to_index[\"The Way of the Dragon\"]] + \"\\n\")\n",
        "print(\"Johnny Stool Pigeon: \" + df_film_metadata[\"overview\"][title_to_index[\"Johnny Stool Pigeon\"]] + \"\\n\")\n",
        "print(\"Doctor X: \" + df_film_metadata[\"overview\"][title_to_index[\"Doctor X\"]] + \"\\n\")\n",
        "print(\"Dream Work: \" + df_film_metadata[\"overview\"][title_to_index[\"Dream Work\"]] + \"\\n\")"
      ],
      "id": "bc5fecf2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c45d364"
      },
      "source": [
        "Es wäre allerdings sehr falsch, unsere Bewertung unserer Ergebnisse nur anhand eines Vorschlages zu testen. Daher geben wir uns weitere Vorschläge zu weiteren bekannten Filmen aus. Hier sieht man jedoch ein besseres Ergebnis, da alle Filme zumindest einmal den Titel Batman tragen. Interessant ist hier zu sehen, dass teilweise Comic-Filme, Dokumentationen über die Personen hinter Batman und alte und neue Batman Filme vertreten sind.  "
      ],
      "id": "1c45d364"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "632387a1"
      },
      "source": [
        "recommend_films_by_title_knn(\"Batman Begins\", movie_matrix, model_knn, n_neighbors=10)"
      ],
      "id": "632387a1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30ed3685"
      },
      "source": [
        "Als letztes Experiment sehen wir uns einen weiteren Film-Klassiker an:"
      ],
      "id": "30ed3685"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2491f7b"
      },
      "source": [
        "recommend_films_by_title_knn(\"Star Wars: Episode II - Attack of the Clones\", movie_matrix, model_knn, n_neighbors=10)"
      ],
      "id": "b2491f7b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ad7e7c4"
      },
      "source": [
        "Abschließend sollten wir erneut festhalten: Die \"Güte\" von unsupervised Modellen ist ohne Domain-Wissen sehr schwer bewertbar. Wenn man einen unsupervised Ansatz plant einzusetzen, so sollte man sich stets über die anschließende Evaluation Gedanken machen. "
      ],
      "id": "3ad7e7c4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dc92123"
      },
      "source": [
        "## Collaborative Filtering - Ergebnis und Auswertung"
      ],
      "id": "6dc92123"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5004298d"
      },
      "source": [
        "Im Gegensatz zum vorgestellten Content-based Ansatz, haben wir für den Collaborative Filtering Ansatz sogenannte Labels. Wir wir bereits in der Session 2.6 erwähnt haben, teilen wir hier auch den Datensatz in \"Test\" und \"Training\". In diesem Fall sind die Ergebnisse weniger einfach \"interpretierbar\", doch haben wir in diesem Fall eine \"Ground Truth\" - also die Bewertung die wirklich gegeben wurde. Als Metrik zur Bewertung der \"Modell-Güte\" betrachten wir den Root Mean Squared Error, der die Abweichung des vorhergesagten Wertes vom tatsächlichen Wert beschreibt. "
      ],
      "id": "5004298d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0afdb56"
      },
      "source": [
        "Um das Modell-Training etwas genauer zu verstehen, können wir uns einmal die Kurve der Loss-Funktion über das Training hinweg ansehen. Der Loss beschreibt den \"Fehler\" (Abweichung wahrer Wert vs. Vorhersage), der während des Trainings (in diesem Falle) entweder auf den Trainings oder den Validierungsdaten existiert. Man sollte das Training erst beenden, wenn sich dieser Wert nur noch sehr minimal verändert."
      ],
      "id": "c0afdb56"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab36614d"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Training Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')"
      ],
      "id": "ab36614d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9f4ab2e"
      },
      "source": [
        "# Test model\n",
        "y_pred = model.predict([test_user_data, test_movie_data])\n",
        "y_true = df_test['rating'].values\n",
        "\n",
        "#  Berechne Root Mean Squared Error\n",
        "rmse = np.sqrt(mean_squared_error(y_pred=y_pred, y_true=y_true))\n",
        "print('RMSE: '+ str(rmse))"
      ],
      "id": "a9f4ab2e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4bdd587"
      },
      "source": [
        "print(\"Wahrer Wert: \" + str(y_true[3]) + \"\\n\") \n",
        "print(\"Vorhersage:  \" + str(y_pred[3][0]))"
      ],
      "id": "d4bdd587",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e34a19d"
      },
      "source": [
        "Auch wenn die obere Art der Auswertung eingängier zu sein scheint, ist die Auswertung des Collaborative Filtering Ansatzes natürlich deutlich objektiver, da wir die wahren Lables/Bewertungen haben und uns damit vergleichen können. "
      ],
      "id": "5e34a19d"
    }
  ]
}