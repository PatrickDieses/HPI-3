{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "ki-praxis",
      "language": "python",
      "name": "ki-praxis"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "2.5 Recommender Systems 1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christianwarmuth/openhpi-kipraxis/blob/main/Woche%202/2_5_Recommender_Systems_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb899884"
      },
      "source": [
        "## Installieren aller Pakete"
      ],
      "id": "eb899884"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "445034f6"
      },
      "source": [
        "# Hier die Kaggle Credentials einfügen (ohne Anführungszeichen)\n",
        "\n",
        "%env KAGGLE_USERNAME=openhpi\n",
        "%env KAGGLE_KEY=das_ist_der_key"
      ],
      "id": "445034f6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ed6ec2c"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "id": "9ed6ec2c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57a34ace"
      },
      "source": [
        "# 2.5 Recommender Systems 1: \n",
        "## Vorschlagssystem mit Content-based Filtering\n",
        "\n",
        "<img width=70% src=\"https://raw.githubusercontent.com/christianwarmuth/openhpi-kipraxis/main/images/jakob-owens-CiUR8zISX60-unsplash%20(2).jpg\">"
      ],
      "id": "57a34ace"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff5e3bf1"
      },
      "source": [
        "Datensatz: \n",
        "\n",
        "### The Movies Dataset\n",
        "Metadaten für über 45.000 Filme. 26 Millionen Bewertungen von über 270.000 NutzerInnen.\n",
        "\n",
        "Quelle: kaggle.com"
      ],
      "id": "ff5e3bf1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eb217d9"
      },
      "source": [
        "## Download Dataset "
      ],
      "id": "1eb217d9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00fc0b24"
      },
      "source": [
        "### Manuell\n",
        "via https://www.kaggle.com/rounakbanik/the-movies-dataset"
      ],
      "id": "00fc0b24"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f172699"
      },
      "source": [
        "### Via API\n",
        "\n",
        "Hinzufügen der kaggle.json\n",
        "Speichern als ~/.kaggle/kaggle.json auf Linux, OSX, oder andere UNIX-based Betriebssysteme und unter C:\\Users<Windows-username>.kaggle\\kaggle.json auf Windows\n",
        "\n",
        "Siehe https://www.kaggle.com/docs/api oder https://github.com/Kaggle/kaggle-api\n",
        "        \n",
        "Beispiel:\n",
        "~/kaggle/kaggle.json\n",
        "\n",
        "{\"username\":\"openHPI\",\"key\":\"das_ist_der_key\"}"
      ],
      "id": "4f172699"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3edd20cd"
      },
      "source": [
        "## Was wir erreichen wollen\n",
        "\n",
        "Wie in der Theorie-Einheit beschrieben, wollen wir Filme vorschlagen, die bisher gesehenen Filmen inhaltlich ähnlich sind. Hat Person 1 also bereits Film A gesehen, so wollen wir Filme vorschlagen, die Film A inhaltlich ähnlich sind. Was inhaltliche Ähnlichkeit genau bedeutet, kann man auf verschiedene Arten interpretieren und umsetzen - wir fokussieren uns hierbei auf die inhaltliche Ähnlichkeit der Kurzbeschreibungen der Filme. \n",
        "\n",
        "<img width=50% src=\"https://raw.githubusercontent.com/christianwarmuth/openhpi-kipraxis/main/images/content_based_filtering.jpg\">"
      ],
      "id": "3edd20cd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92f831a8"
      },
      "source": [
        "# Einlesen der Daten"
      ],
      "id": "92f831a8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfd8e57d"
      },
      "source": [
        "!pip3 install kaggle\n",
        "!kaggle datasets download -d rounakbanik/the-movies-dataset"
      ],
      "id": "bfd8e57d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-lH0IrGr4w4"
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"the-movies-dataset.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"\")"
      ],
      "id": "m-lH0IrGr4w4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuxsUCjesKL3"
      },
      "source": [
        "import pandas as pd\n",
        "df_film_metadata = pd.read_csv(\"movies_metadata.csv\", low_memory=False)"
      ],
      "id": "DuxsUCjesKL3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a64ffa14"
      },
      "source": [
        "## Beschreibung eines Beispiel-Films:"
      ],
      "id": "a64ffa14"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17dd38b7"
      },
      "source": [
        "print(\"Film-Titel: \" + df_film_metadata[\"title\"][9] + \"\\n\")\n",
        "print(\"Film-Beschreibung: \" + df_film_metadata[\"overview\"][9])"
      ],
      "id": "17dd38b7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3a0f686"
      },
      "source": [
        "Wir betrachten erneut einmal die verschiedenen Titel der Filme. Hier sieht man erneut die Gesamtanzahl aller Filme mit **45466**. Auffällig ist auch, das ein Film hier in dieser Ansicht keinen englischen Titel trägt. "
      ],
      "id": "c3a0f686"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a687c986"
      },
      "source": [
        "df_film_metadata[\"original_title\"]"
      ],
      "id": "a687c986",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9108404f"
      },
      "source": [
        "Wir wollen auch kurz untersuchen, ob das für uns im Laufe der Analyse zum Problem wird. Grundsätzlich sollte man als Input eines Machine Learning Modells stets auf identische Einheiten achten und so auch auf gleiche Sprachen bei Textfeldern. Das ist hier jedoch kein Problem, da wir die Spalte mit den Original-Titeln betrachtet haben. Die Spalte \"title\" hingegen enthält den Titel in übersetzer Form und auch die \"overview\" Spalte enthält Englisch. "
      ],
      "id": "9108404f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e84e7e5"
      },
      "source": [
        "print(\"Original-Film-Titel: \" + df_film_metadata[\"original_title\"][45461] + \"\\n\")\n",
        "print(\"Film-Titel: \" + df_film_metadata[\"title\"][45461] + \"\\n\")\n",
        "print(\"Film-Beschreibung: \" + df_film_metadata[\"overview\"][45461])"
      ],
      "id": "5e84e7e5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c91175f"
      },
      "source": [
        "## Filtern fehlender Werte"
      ],
      "id": "3c91175f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c42cd24d"
      },
      "source": [
        "Da wir Filme anhand deren Kurzbeschreibung verleichen wollen, so wollen wir natürlich nur jene Filme beachten, die auch eine Beschreibung enthalten. Gibt es überhaupt Filme ohne Kurzbeschreibung?"
      ],
      "id": "c42cd24d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16893936"
      },
      "source": [
        "df_film_metadata[df_film_metadata['overview'].isna()]"
      ],
      "id": "16893936",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ae6f5aa3"
      },
      "source": [
        "df_film_metadata = df_film_metadata[df_film_metadata['overview'].notna()]\n",
        "df_film_metadata = df_film_metadata.reset_index()"
      ],
      "id": "ae6f5aa3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0c7525f"
      },
      "source": [
        "# Ähnlichkeitsberechnungen "
      ],
      "id": "b0c7525f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "856184ed"
      },
      "source": [
        "Etwas Theorie: **Count Vectorizer**\n",
        "\n",
        "Bei einem Count Vectorizer konvertiert man Texte in eine Matrix mit den Anzahlen der Vorkommnisse der verschiedenen Tokens. Ein Token ist eine Sequenz von Zeichen (z.B. \"Christian\" oder \"Johannes\", jedoch kann auch \"Johannes und Christian\" ein einzelner Token sein). "
      ],
      "id": "856184ed"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0b1d033"
      },
      "source": [
        "text = [\"Künstliche Intelligenz und Maschinelles Lernen in der Praxis\", \n",
        "        \"Künstliche Intelligenz und maschinelles Lernen für Einsteiger\", \n",
        "       \"Connected Healthcare: Gesundheitsdaten im Alltag erfassen und analysieren\"]\n",
        "\n",
        "\n",
        "cv = CountVectorizer()\n",
        "count_matrix = cv.fit_transform(text)\n",
        "np.set_printoptions(precision=3)\n",
        "print(\"Feature-Names: \" + str(cv.get_feature_names()) + \"\\n\")\n",
        "print(\"Matrix: \\n\" + str(count_matrix.todense()))"
      ],
      "id": "a0b1d033",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c05318a"
      },
      "source": [
        "Etwas Theorie: **Tf-idf Vectorizer**\n",
        "\n",
        "Bei einem Tf-idf Vectorizer misst man die inverse Dokumenthäufigkeit von Tokens. Das Vorkommen von seltener Begriffe ist hier relevanter als das Vorkommen von häufigen Wörtern (z.B. \"und\" oder \"das\").\n",
        "\n",
        "Der Tf-idf Wert eines Tokens wird wie folgt berechnet:\n",
        "\n",
        "$$ TF(w,d) = \\frac{Anzahl\\; von\\; Wort\\; w\\; in\\; Dokument\\; d}{Gesamtanzahl\\; von\\; Woertern\\; in\\; Dokument\\; d} $$\n",
        "\n",
        "$$ IDF(w, D) = ln \\left ( \\;\\frac{Gesamtanzahl\\;  von\\; Dokumenten\\; (N)\\; in\\; Corpus\\; D }{Anzahl\\; von\\; Dokumenten\\; die\\; Wort\\; w\\; enthalten}\\;\\right ) $$\n",
        "\n",
        "Der Gesamtwert berechnet sich wie folgt:\n",
        "\n",
        "$$TFIDF(w,d,D) = TF(w,d) * IDF(w,D)$$\n"
      ],
      "id": "7c05318a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8bb876b"
      },
      "source": [
        "text = [\"Künstliche Intelligenz und Maschinelles Lernen in der Praxis\", \n",
        "        \"Künstliche Intelligenz und maschinelles Lernen für Einsteiger\", \n",
        "       \"Connected Healthcare: Gesundheitsdaten im Alltag erfassen und analysieren\"]\n",
        "\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf.fit_transform(text)\n",
        "np.set_printoptions(precision=3)\n",
        "print(\"Feature-Names: \" + str(tfidf.get_feature_names()) + \"\\n\")\n",
        "print(\"Matrix: \\n\" + str(tfidf_matrix.todense()))"
      ],
      "id": "d8bb876b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae41560b"
      },
      "source": [
        "# Berechnung der Ähnlichkeit auf Film-Beschreibungen"
      ],
      "id": "ae41560b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d45dc665"
      },
      "source": [
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(df_film_metadata['overview'])"
      ],
      "id": "d45dc665",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42080a6a"
      },
      "source": [
        "Wie viele Wörter wurden jetzt bei dieser Tfidf Vektorisierung jetzt beachtet? Dafür geben wir uns einmal die Form der resultierenden Matrix aus. Hier sehen wir, dass die Matrix 44512x75827 groß ist. 44512 ist die Anzahl der Filme, so haben wir also 75827 Features (ein Feature ist hier ein Wort). "
      ],
      "id": "42080a6a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bc2065d"
      },
      "source": [
        "tfidf_matrix.shape"
      ],
      "id": "2bc2065d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97d2dd36"
      },
      "source": [
        "Wenn wir die Ähnlichkeiten zwischen Filmen berechnen, dann müssen wir ermöglichen, mit dem Titel auf die Positionen in der Matrix zugreifen zu können. Hierfür kreieren wir eine Art Dictionary, um von dem jeweiligen Titel auf die Position des Films zu kommen. "
      ],
      "id": "97d2dd36"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d89cef70"
      },
      "source": [
        "title_to_index = pd.Series(df_film_metadata.index, index=df_film_metadata['title'])"
      ],
      "id": "d89cef70",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e53beefb"
      },
      "source": [
        "title_to_index"
      ],
      "id": "e53beefb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adf38cb7"
      },
      "source": [
        "# K-Nearest-Neighbors\n",
        "\n"
      ],
      "id": "adf38cb7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "059719ab"
      },
      "source": [
        "Um die Ähnlichkeiten zwischen den Filmen zu ermitteln nutzen wir den K-Nearest-Neighbor Ansatz. Als Ähnlichkeitsmaß nehmen wir die Cosine Similarity zwischen den tfidf-Vectoren. Die Cosine Similarity ist eine von vielen verschiedenen Möglichkeiten \"Ähnlichkeit in hochdimensionalem Raum\" zu berechnen."
      ],
      "id": "059719ab"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e06f2e1"
      },
      "source": [
        "movie_matrix=csr_matrix(tfidf_matrix)\n",
        "model_knn= NearestNeighbors(metric='cosine', algorithm='auto', n_neighbors=10, n_jobs=-1)"
      ],
      "id": "4e06f2e1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e8e3621"
      },
      "source": [
        "def recommend_films_by_title_knn(title, data, model, n_neighbors):\n",
        "    model.fit(data)\n",
        "    movie_idx = title_to_index[title]\n",
        "    sim_scores, movie_indices = model.kneighbors(data[movie_idx], n_neighbors=n_neighbors+1)\n",
        "    sim_scores = sim_scores.squeeze().tolist()\n",
        "    recommendation_list = []\n",
        "    for idx, movie_idx in enumerate(movie_indices.squeeze().tolist()):\n",
        "        recommendation_list.append({'Title':df_film_metadata['title'][movie_idx],'Distance':sim_scores[idx]})\n",
        "    return pd.DataFrame(recommendation_list).sort_values(by=['Distance'], ascending=False).reset_index(drop=True)[:-1]"
      ],
      "id": "0e8e3621",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "564183fd"
      },
      "source": [
        "Wir wollen uns nun einmal einen Vorschlag zu dem Film \"Golden Eye\", also einem James-Bond Film ausgeben. "
      ],
      "id": "564183fd"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "681ce00a"
      },
      "source": [
        "recommend_films_by_title_knn(\"GoldenEye\", movie_matrix, model_knn, n_neighbors=10)"
      ],
      "id": "681ce00a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60f34879"
      },
      "source": [
        "Die Ergebnisse sehen bereits sehr gut aus - nahezu alle Filme sind tatsächlich auch aus der James Bond Reihe - inhaltlich also sehr ähnlich. Eine detailiertere Auswertung werden wir in Einheit **2.7 Ergebnis und Auswertung etwas genauer ansehen**. "
      ],
      "id": "60f34879"
    }
  ]
}