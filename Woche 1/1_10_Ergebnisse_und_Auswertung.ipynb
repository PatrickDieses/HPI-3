{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "name": "1.10 Ergebnisse und Auswertung.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/christianwarmuth/openhpi-kipraxis/blob/main/Woche%201/1_10_Ergebnisse_und_Auswertung.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip3 install scikit-learn==1.0.0"
      ],
      "outputs": [],
      "metadata": {
        "id": "VcPr-DWxqoYc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import os # u.a. zur Entwicklugn plattformübergreifender Systempfade\n",
        "import pandas as pd # Datenmanagement\n",
        "import numpy as np # Hilfsfunktionen für mathematische Operationen\n",
        "\n",
        "# Datenvisualisierung\n",
        "import seaborn as sns \n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas.plotting import scatter_matrix\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split # Datensplits\n",
        "from sklearn.linear_model import LinearRegression # Machine Learning\n",
        "from sklearn import metrics # Modellevaluierung\n",
        "\n",
        "## eigene Funktionen\n",
        "def filter_df_by_proximity(df, proximity):\n",
        "    return df.loc[df[\"ocean_proximity\"] == proximity]\n",
        "\n",
        "def engineer_features(df):\n",
        "    df[\"ratio_bedrooms\"] = df[\"total_bedrooms\"] / df[\"total_rooms\"]\n",
        "    df[\"people_per_household\"] = df[\"population\"] / df[\"households\"]\n",
        "    return df\n",
        "\n",
        "def get_features_and_targets(df):\n",
        "    X = df.drop([\"median_house_value\"], axis=1).values\n",
        "    y = np.stack(df[\"median_house_value\"])\n",
        "    return X, y"
      ],
      "outputs": [],
      "metadata": {
        "id": "d2d1717a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import os\n",
        "import tarfile\n",
        "import urllib.request\n",
        "\n",
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
        "HOUSING_PATH = os.getcwd()\n",
        "FILE_PATH = \"housing.csv\"\n",
        "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
        "\n",
        "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
        "    if not os.path.isdir(housing_path):\n",
        "        os.makedirs(housing_path)\n",
        "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
        "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
        "    housing_tgz = tarfile.open(tgz_path)\n",
        "    housing_tgz.extractall(path=housing_path)\n",
        "    housing_tgz.close()\n",
        "    \n",
        "fetch_housing_data()\n",
        "\n",
        "df = pd.read_csv(FILE_PATH) # Wir lesen die Datei housing.csv ein\n",
        "\n",
        "df = df.dropna() # löscht alle Zeile mit fehlenden Attributen\n",
        "df = df.reset_index(drop=True) # zählt unsere Daten neu durch\n",
        "\n",
        "description = df.describe()\n",
        "\n",
        "bins = [0] + list(description[\"median_house_value\"][\n",
        "    [\"25%\", \"50%\", \"75%\"]\n",
        "].astype(int)) + [np.inf]\n",
        "\n",
        "df[\"house_cat\"] = pd.cut(\n",
        "    df[\"median_house_value\"],\n",
        "    bins=bins,\n",
        "    labels=[\"0 - 25%\", \"25 - 50%\", \"50 - 75%\", \"75 - 100%\"]\n",
        ")\n",
        "\n",
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=0)\n",
        "for train_index, test_index in split.split(df, df[\"house_cat\"]):\n",
        "    df_train = df.loc[train_index]\n",
        "    df_test = df.loc[test_index]\n",
        "    \n",
        "df_train = df_train.drop(\"house_cat\", axis=1)\n",
        "df_test = df_test.drop(\"house_cat\", axis=1)\n",
        "\n",
        "df_train = df_train.drop(filter_df_by_proximity(df_train, \"ISLAND\").index)\n",
        "df_test = df_test.drop(filter_df_by_proximity(df_test, \"ISLAND\").index)\n",
        "\n",
        "df_train = engineer_features(df_train)\n",
        "df_test = engineer_features(df_test)\n",
        "\n",
        "df_train_ml = pd.get_dummies(df_train) # One-Hot Encoding\n",
        "df_test_ml = pd.get_dummies(df_test)\n",
        "\n",
        "X_train, y_train = get_features_and_targets(df_train_ml)\n",
        "X_test, y_test = get_features_and_targets(df_test_ml)\n",
        "\n",
        "clf = LinearRegression()\n",
        "clf.fit(X_train, y_train)"
      ],
      "outputs": [],
      "metadata": {
        "id": "57551d12"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.10 Ergebnis und Auswertung\n",
        "\n",
        "Wir können nun unser Modell für Prognosen verwenden:"
      ],
      "metadata": {
        "id": "bf248b7f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "predictions = clf.predict(X_test)"
      ],
      "outputs": [],
      "metadata": {
        "id": "14e2e7e2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Schauen wir uns die Prognosen unseres Modells einmal im Vergleich zu einigen echten Werten an:"
      ],
      "metadata": {
        "id": "d70cc6d6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(\"Prediction\\t|True Value\")\n",
        "print(\"-\"*30)\n",
        "for idx, (pred, annotation) in enumerate(zip(predictions, y_test)):\n",
        "    if idx == 10:\n",
        "        break\n",
        "    pred = int(pred)\n",
        "    annotation = int(annotation)\n",
        "    print(f\"{pred}\\t\\t|{annotation}\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "863ab954"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Auch hier sehen wir, dass das Modell z.T. starke Fehlprognosen liefert (mit fast 100.000€ Unterschied zum Realwert); an vielen Stellen liefert das Modell jedoch auch schon sehr gute Prognosen. Wir können einen High-Level Überblick erhalten, indem wir Kennzahlen berechnen:"
      ],
      "metadata": {
        "id": "83ccac23"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$MAE(y, \\hat{y}) = \\frac{1}{n}\\sum_{i=0}^{n}{|y_{i} - \\hat{y}_{i}|}$\n",
        "\n",
        "\"Mit welcher Abweichung vom Realwert können wir durchschnittlich rechnen?\""
      ],
      "metadata": {
        "id": "703d2ed4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$R^{2}(y, \\hat{y}) = 1 - \\frac{\\frac{1}{n}\\sum_{i=0}^{n}{|y_{i} - \\hat{y}_{i}|}}{\\frac{1}{n}\\sum_{i=0}^{n}{|y_{i} - \\overline{y}_{i}|}}$\n",
        "\n",
        "\"Wie viel der Varianz von y (unserem Zielwert) wird durch die unabhängigen Variablen des Modells erklärt\"; stark vereinfacht: wenn der Wert = 100% ist, haben wir eine perfekte Prognose. Wenn er 0% ist, ist unsere Prognose genau so gut, wie der Mittelwert der Daten. Ein Wert < 0% (möglich) bedeutet, dass wir eine schlechtere Prognose als den Mittelwert geben."
      ],
      "metadata": {
        "id": "2a0d5878"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "mae = metrics.mean_absolute_error(y_test, predictions)\n",
        "mae_ratio = metrics.mean_absolute_percentage_error(y_test, predictions)\n",
        "r2_score = metrics.r2_score(y_test, predictions)"
      ],
      "outputs": [],
      "metadata": {
        "id": "8cf3c378"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(f\"Wir können durchschnittlich mit einem Fehler von {np.round(mae)} rechnen;\")\n",
        "print(f\"Das entspricht im Schnitt einer Fehlerquote von {np.round(mae_ratio * 100)}%;\")\n",
        "print(f\"Der R^2 Werte liegt bei {np.round(r2_score * 100)}%\")"
      ],
      "outputs": [],
      "metadata": {
        "scrolled": true,
        "id": "d70db6af"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Schauen wir uns das zuletzt noch an einem einzelnen Beispiel im Detail an:"
      ],
      "metadata": {
        "id": "c92a7160"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df_test.iloc[0]"
      ],
      "outputs": [],
      "metadata": {
        "id": "263c10a0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In ML-Format sieht der Record wie folgt aus:"
      ],
      "metadata": {
        "id": "1730cff3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "X_test[0]"
      ],
      "outputs": [],
      "metadata": {
        "id": "04a3b387"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Und die Prognose ist:"
      ],
      "metadata": {
        "id": "8d845558"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "single_pred = clf.predict([X_test[0]])[0]\n",
        "print(f\"Die Prognose liegt bei {single_pred}.\")\n",
        "print(f\"Der Realwert war {y_test[0]}.\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "5f55dd10"
      }
    }
  ]
}